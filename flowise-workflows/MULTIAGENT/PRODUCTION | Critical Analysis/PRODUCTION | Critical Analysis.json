{"nodes":[{"id":"seqStart_0","position":{"x":-1795.2137274350782,"y":-122.40607708214543},"type":"customNode","data":{"id":"seqStart_0","label":"Start","version":2,"name":"seqStart","type":"Start","baseClasses":["Start"],"category":"Sequential Agents","description":"Starting point of the conversation","inputParams":[],"inputAnchors":[{"label":"Chat Model","name":"model","type":"BaseChatModel","description":"Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat","id":"seqStart_0-input-model-BaseChatModel"},{"label":"Agent Memory","name":"agentMemory","type":"BaseCheckpointSaver","description":"Save the state of the agent","optional":true,"id":"seqStart_0-input-agentMemory-BaseCheckpointSaver"},{"label":"State","name":"state","type":"State","description":"State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.","optional":true,"id":"seqStart_0-input-state-State"},{"label":"Input Moderation","description":"Detect text that could generate harmful output and prevent it from being sent to the language model","name":"inputModeration","type":"Moderation","optional":true,"list":true,"id":"seqStart_0-input-inputModeration-Moderation"}],"inputs":{"model":"{{chatOpenAI_0.data.instance}}","agentMemory":"","state":"{{seqState_0.data.instance}}","inputModeration":""},"outputAnchors":[{"id":"seqStart_0-output-seqStart-Start","name":"seqStart","label":"Start","description":"Starting point of the conversation","type":"Start"}],"outputs":{},"selected":false},"width":300,"height":378,"selected":false,"positionAbsolute":{"x":-1795.2137274350782,"y":-122.40607708214543},"dragging":false},{"id":"chatOpenAI_0","position":{"x":-2135.2205553499634,"y":-124.87869272872057},"type":"customNode","data":{"loadMethods":{},"label":"ChatOpenAI","name":"chatOpenAI","version":8.1,"type":"ChatOpenAI","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg","category":"Chat Models","description":"Wrapper around OpenAI large language models that use the Chat endpoint","baseClasses":["ChatOpenAI","BaseChatModel","BaseLanguageModel","Runnable"],"credential":"a0fffb09-1722-4f82-8532-e2bba4363b32","inputs":{"cache":"","modelName":"gpt-4o-mini","temperature":"0","streaming":true,"maxTokens":"","topP":"","frequencyPenalty":"","presencePenalty":"","timeout":"","strictToolCalling":"","stopSequence":"","basepath":"","proxyUrl":"","baseOptions":"","allowImageUploads":false,"imageResolution":"high","reasoningEffort":"low"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js","inputAnchors":[{"label":"Cache","name":"cache","type":"BaseCache","optional":true,"id":"chatOpenAI_0-input-cache-BaseCache"}],"inputParams":[{"label":"Connect Credential","name":"credential","type":"credential","credentialNames":["openAIApi"],"id":"chatOpenAI_0-input-credential-credential"},{"label":"Model Name","name":"modelName","type":"asyncOptions","loadMethod":"listModels","default":"gpt-4o-mini","id":"chatOpenAI_0-input-modelName-asyncOptions"},{"label":"Temperature","name":"temperature","type":"number","step":0.1,"default":0.9,"optional":true,"id":"chatOpenAI_0-input-temperature-number"},{"label":"Streaming","name":"streaming","type":"boolean","default":true,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-streaming-boolean"},{"label":"Max Tokens","name":"maxTokens","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-maxTokens-number"},{"label":"Top Probability","name":"topP","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-topP-number"},{"label":"Frequency Penalty","name":"frequencyPenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-frequencyPenalty-number"},{"label":"Presence Penalty","name":"presencePenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-presencePenalty-number"},{"label":"Timeout","name":"timeout","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-timeout-number"},{"label":"Strict Tool Calling","name":"strictToolCalling","type":"boolean","description":"Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-strictToolCalling-boolean"},{"label":"Stop Sequence","name":"stopSequence","type":"string","rows":4,"optional":true,"description":"List of stop words to use when generating. Use comma to separate multiple stop words.","additionalParams":true,"id":"chatOpenAI_0-input-stopSequence-string"},{"label":"BasePath","name":"basepath","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-basepath-string"},{"label":"Proxy Url","name":"proxyUrl","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-proxyUrl-string"},{"label":"BaseOptions","name":"baseOptions","type":"json","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-baseOptions-json"},{"label":"Allow Image Uploads","name":"allowImageUploads","type":"boolean","description":"Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.","default":false,"optional":true,"id":"chatOpenAI_0-input-allowImageUploads-boolean"},{"label":"Image Resolution","description":"This parameter controls the resolution in which the model views the image.","name":"imageResolution","type":"options","options":[{"label":"Low","name":"low"},{"label":"High","name":"high"},{"label":"Auto","name":"auto"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-imageResolution-options"},{"label":"Reasoning Effort","description":"Constrains effort on reasoning for reasoning models. Only applicable for o1 models","name":"reasoningEffort","type":"options","options":[{"label":"Low","name":"low"},{"label":"Medium","name":"medium"},{"label":"High","name":"high"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-reasoningEffort-options"}],"outputs":{},"outputAnchors":[{"id":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","name":"chatOpenAI","label":"ChatOpenAI","description":"Wrapper around OpenAI large language models that use the Chat endpoint","type":"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"}],"id":"chatOpenAI_0","selected":false},"width":300,"height":664,"selected":false,"positionAbsolute":{"x":-2135.2205553499634,"y":-124.87869272872057},"dragging":false},{"id":"seqCondition_0","position":{"x":-795.1010517858365,"y":-18.00967812176765},"type":"customNode","data":{"label":"Condition","name":"seqCondition","version":2.1,"type":"Condition","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Condition/condition.svg","category":"Sequential Agents","description":"Conditional function to determine which route to take next","baseClasses":["Condition"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-7.-conditional-node","inputs":{"conditionName":"step-identification","sequentialNode":["{{seqStart_0.data.instance}}","{{seqStart_0.data.instance}}"],"condition":"","selectedConditionFunctionTab_seqCondition_0":"conditionFunction","conditionFunction":"const messages = $flow.state.messages;\nconst lastMessage = messages[messages.length - 1];\nconst content = lastMessage.content;\n\nif (content.includes(\"CORRIGE_JSON\")) {\n  return \"Adjust JSON\";\n}\n\nif (content.startsWith(\"ANALISE_\")) {\n   return \"ANALISE_CRITICA\";\n}\n\nreturn \"Critical Analysis\";\n"},"outputs":{"output":"next"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Condition/Condition.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[{"label":"Condition Name","name":"conditionName","type":"string","optional":true,"placeholder":"If X, then Y","id":"seqCondition_0-input-conditionName-string"},{"label":"Condition","name":"condition","type":"conditionFunction","tabIdentifier":"selectedConditionFunctionTab","tabs":[{"label":"Condition (Table)","name":"conditionUI","type":"datagrid","description":"If a condition is met, the node connected to the respective output will be executed","optional":true,"datagrid":[{"field":"variable","headerName":"Variable","type":"freeSolo","editable":true,"loadMethod":["getPreviousMessages","loadStateKeys"],"valueOptions":[{"label":"Total Messages (number)","value":"$flow.state.messages.length"},{"label":"First Message Content (string)","value":"$flow.state.messages[0].content"},{"label":"Last Message Content (string)","value":"$flow.state.messages[-1].content"},{"label":"Global variable (string)","value":"$vars.<variable-name>"}],"flex":0.5,"minWidth":200},{"field":"operation","headerName":"Operation","type":"singleSelect","valueOptions":["Contains","Not Contains","Start With","End With","Is","Is Not","Is Empty","Is Not Empty","Greater Than","Less Than","Equal To","Not Equal To","Greater Than or Equal To","Less Than or Equal To"],"editable":true,"flex":0.4,"minWidth":150},{"field":"value","headerName":"Value","flex":1,"editable":true},{"field":"output","headerName":"Output Name","editable":true,"flex":0.3,"minWidth":150}]},{"label":"Condition (Code)","name":"conditionFunction","type":"code","description":"Function to evaluate the condition","hint":{"label":"How to use","value":"\n1. Must return a string value at the end of function. For example:\n    ```js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n    For example, to get the last message content:\n    ```js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    ```\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"hideCodeExecute":true,"codeExample":"const state = $flow.state;\n                \nconst messages = state.messages;\n\nconst lastMessage = messages[messages.length - 1];\n\n/* Check if the last message has content */\nif (lastMessage.content) {\n    return \"Agent\";\n}\n\nreturn \"End\";","optional":true}],"id":"seqCondition_0-input-condition-conditionFunction"}],"outputAnchors":[{"name":"output","label":"Output","type":"options","description":"","options":[{"id":"seqCondition_0-output-analise_critica-Condition","name":"analise_critica","label":"ANALISE_CRITICA","type":"Condition","isAnchor":true},{"id":"seqCondition_0-output-adjustJson-Condition","name":"adjustJson","label":"Adjust JSON","type":"Condition","isAnchor":true},{"id":"seqCondition_0-output-criticalAnalysis-Condition","name":"criticalAnalysis","label":"Critical Analysis","type":"Condition","isAnchor":true}],"default":"next"}],"id":"seqCondition_0","selected":false},"width":300,"height":520,"selected":false,"dragging":false,"positionAbsolute":{"x":-795.1010517858365,"y":-18.00967812176765}},{"id":"seqEnd_2","position":{"x":3876.422694432113,"y":120.08561088307323},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_4.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_2","selected":false},"width":300,"height":142,"positionAbsolute":{"x":3876.422694432113,"y":120.08561088307323},"selected":false,"dragging":false},{"id":"seqAgent_4","position":{"x":3450.050078158654,"y":125.8205866161706},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"critical-analysis","systemMessagePrompt":"Você atuará como um OCR inteligente para processar imagens e extrair dados textuais relevantes. Será fornecido um plain-text contendo a pré-extração dos caracteres do documento. Sua tarefa é estruturar essas informações em formato markdown, organizando chaves e valores de forma hierárquica, respeitando headers, tabelas e demais elementos estruturais do documento original encontrado nas imagens carregadas. Os dados extraídos devem possuir alta precisão, garantindo que nenhuma informação seja adicionada ou interpretada erroneamente. Após a extração, converta o markdown gerado para um JSON estruturado, preservando corretamente a relação entre os dados e extraindo somente as informações contidas no template citado abaixo, usando como fonte o documento carregado e o markdown, preencha os seguintes dados:\n  - HS Code: [...] (Pesquise chaves com os nomes \"Tariff Number\", \"Tariff No.\", \"HS Code\", \"Harmonized System Code\", \"Tariff Code\". Nunca pode ser confundido com o NCM. Se um valor for encontrado e corresponder ao NCM extraído, rejeite-o e continue a busca. *NÃO* extraia CNPJs, CPFs, números de telefone ou outros códigos numéricos não relacionados. Se não encontrar um valor válido condizente, indique \"Não identificado\". Exemplo: \"HS Code: 850440\" → HS Code: \"850440\".)\n  - NCM: [ ... ] ( O valor do NCM terá obrigatoriamente 8 dígitos numéricos.  Os valores devem obrigatoriamente estar próximos à chaves com o nome \"NCM\". Desconsidere qualquer valor que não atenda os requisitos. \n  - INCOTERM: (sempre com 3 letras: EXW, FCA, FAS, FOB, CPT, CIP, CFR, CIF, DAP, DPU, DDP)\n  - Local INCOTERM: (Busque o texto imediatamente após a sigla de um INCOTERM Válido (EXW, FCA, FAS, FOB, CPT, CIP, CFR, CIF, DAP, DPU, DDP). Esse texto deve representar o nome de um porto, cidade ou local de entrega e pode conter mais de uma palavra. Extraia todo o conteúdo até o próximo delimitador, como uma vírgula, um ponto, ou uma quebra de linha. Exemplo: \"FOB Shanghai Port Terminal 3\" → Local INCOTERM: \"Shanghai Port Terminal 3\".)\n  - Peso bruto estimado: (Busque por termos como \"Gross Weight\", \"Peso Bruto\", \"Poids Brut\", \"Gewicht\", \"G Weight\", seguidos de um valor numérico acompanhado de uma unidade válida (kg, lbs, mt, etc). Se houver múltiplos valores, priorize o maior peso total indicado no documento. Exemplo: \"Gross Weight: 12,500 kg\" → Peso bruto estimado: \"12,500 KG)\n  - M3 estimada/quantidade de volumes e dimensões: (Procure por \"Volume\", \"Cubic Meters\", \"CBM\", \"M³\", \"Dimensões\", \"Quantidade de Volumes\", \"Quantidade de Caixas\", \"Quantidade de Pallets\", \"Packing\", \"Bultos\", \"Packaging\", \"cartons\", \"pallets\", \"HC\", \"NOR\", etc.  Traga o volume total estimado com sua respectiva unidade de medida ou a quantidade de volumes multiplicado pelas dimensões. Geralmente descreve como a mercadoria está comportada.\n  - País de origem/fabricação: (Busque por termos como \"Country of Origin\", \"Made in\", \"Fabricado em\", \"Origine\", \"Herkunft\", \"Product Origin\", \"Country of Provenance\" seguidos de um nome de país.)\nPaís de embarque: (Busque por termos como \"Country of Shipment\", \"Port of Loading\", \"Port Loading\", \"País de Embarque\", \"Lieu d'embarquement\", \"Verladehafen\", \"Pto. Emb.\", \"Ponto de embarque\" geralmente seguidos do nome de um local. Se o valor encontrado for uma cidade em vez de um país, identifique a qual país essa cidade pertence. Exemplo: \"Port of Loading: Hamburg\" → País de Embarque: \"Alemanha\".\n  - Estado do Importador: (Busque a sigla do estado brasileiro associada ao importador, geralmente encontrada próxima a termos como \"Consignee\", \"Importer Address\", \"Endereço do Importador\", \"Destinatário\", \"Importador\", \"Final Destination\", \"Buyer\", \"TO:\" ou qualquer outro que indique o comprador relacionado àquele processo. Dê prioridade a siglas de dois caracteres que correspondam a estados do Brasil (exemplo: SP, RJ, MG, PR). Caso o estado apareça por extenso, converta para a sigla correspondente. Extraia somente a sigla do estado, evitando outras informações no endereço.)\n   - Descrição da mercadoria: (Busque pela descrição da mercadoria equivalente ao NCM encontrado, podendo ela estar identificada com uma label de \"descrição\" no documento ou não.)\n    - Valor da mercadoria: (Encontre o valor unitário da mercadoria em questão, referente ao NCM encontrado. O valor deve sempre estar identificado em uma unidade monetária e deve ser referente à unidade, não ao valor total da mercadoria ou do documento como um todo.)\n\nInstruções:\n  1. Se alguma informação não for encontrada na imagem, traga a chave e insira o seu valor como null.\n  2. Formate a resposta final exclusivamente como um JSON de linha única, onde cada chave esteja corretamente associada ao valor correspondente.\n  3. Não utilize formatação adicional, como Markdown, espaços extras ou quebras de linha.\n  4. O NCM sempre será um array único, NUNCA será um objeto.\n5. O HS Code sempre será um array único, NUNCA será um objeto.\n6. **Somente** se  enfrentar algum erro e não encontrar nenhuma informação retorne o JSON com todas chaves como null\n7. **Nunca** retorne uma mensagem de texto\n\nPara o NCM:\n- Considere que o ncm sempre será um array único, ou seja, TODAS entradas serão diretamente acessíveis, ao identificar novos NCMS apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"10203040\", \"50607080\"], se for identificado um novo NCM \"80709010\", por exemplo, ao adicionar teremos: [\"10203040\", \"50607080\", \"80709010\"]. Obs: Apenas NCMS de 8 DÍGITOS.\n\nPara o HSCODE:\n- Considere que o 'HS Code' sempre será um array único, ou seja, TODAS entradas serão diretamente acessíveis, ao identificar novos HS Codes apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo HS Code \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\nNUNCA retorne uma mensagem de texto.\n\nExemplo de resposta:\n  (\"HS Code\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"NCM\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"INCOTERM\": \"FOB\", \"Local do INCOTERM\": \"Porto\", \"Peso bruto estimado\": \"1000kg\", \"M3 estimada/quantidade de volumes e dimensões\": \"50m3\", \"País de origem/fabricação\": \"Brasil\", \"País de embarque\": \"Brasil\", \"Estado do Importador\": \"SP\")\n\nRegras de Extração:\n- Foque na precisão: Verifique se os dados extraídos fazem sentido no contexto.\n- Elimine falsos positivos: Ignore ruídos ou fragmentos não relacionados.\n- Corrija erros comuns de OCR: Como quebras de linha indevidas, caracteres corrompidos (ex: \"1l\" para \"11\"), erros em datas e formatação inconsistente.\nErros comuns e como lidar:\n- Texto truncado ou fragmentado: Se encontrar partes de dados quebradas, tente reconstruir com base no contexto.\n- Reconhecimento incorreto de caracteres: Exemplo: \"O00l\" pode ser \"001\" ou \"00l\". Use padrões comuns para validar.\n- Quebras de linha indevidas: Se um campo estiver fragmentado, reconstrua-o corretamente antes de processar.","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":"","sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"{{chatOpenAI_1.data.instance}}","interrupt":"","promptValues":"","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_4":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_4-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_4-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_4-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_4-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_4-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_4-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_4-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_4-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_4-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_4-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_4-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_4-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_4-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_4-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_4-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_4","selected":false},"width":300,"height":853,"selected":false,"positionAbsolute":{"x":3450.050078158654,"y":125.8205866161706},"dragging":false},{"id":"seqAgent_1","position":{"x":2421.1700102411532,"y":-1063.1636016950542},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"adjust-json","systemMessagePrompt":"Você receberá um json e um texto.\n\n  - Traga APENAS os seguintes dados encontrados no texto(Esses nomes podem estar em outro idioma, ou com nomes semelhantes):\n  - HS Code: [...] (Pesquise chaves com o nome como \"Tariff Number\", \"Tariff No.\", \"HS Code\") \n  - NCM: [ ... ] (Pesquise apenas chaves com o nome NCM)\n  - INCOTERM e Local\n  - Peso bruto estimado\n  - M3 estimada/quantidade de volumes e dimensões\n  - País de origem/fabricação\n  - País de embarque\n  - Estado do Importador\n  - Descrição da mercadoria\n  - Valor da mercadoria\n\n- Mude no os campos no JSON recebido APENAS os dados que forem encontrados no texto.\n\n- Sempre formate a resposta final em um JSON de linha única para correlacionar as chaves e valores. Nunca utilize formatação Markdown. Certifique-se de que não haja espaços ou quebras de linha entre os elementos do objeto na resposta final.\n\n- Caso não encontre algum dos dados retorne o valor da chave como null.\n\n- SEMPRE retorne um JSON, NUNCA escreva uma mensagem\n\n- O NCM sempre será um array único, NUNCA será um objeto.\n\n- O HS Code sempre será um array único, NUNCA será um objeto.\n\n- Considere que o ncm sempre será um array único, ou seja, TODAS entradas serão diretamente acessíveis, ao identificar novos NCMS apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo NCM \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\n- Considere que o HS Code sempre será um array único, ou seja, TODAS entradas serão diretamente acessíveis, ao identificar novos HS Codes apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo HS Code \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\nExemplo de resposta:\n  (\"HS Code\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"NCM\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"INCOTERM\": \"FOB\", \"Local do INCOTERM\": \"Porto\", \"Peso bruto estimado\": \"1000kg\", \"M3 estimada/quantidade de volumes e dimensões\": \"50m3\", \"País de origem/fabricação\": \"Brasil\", \"País de embarque\": \"Brasil\", \"Estado do Importador\": \"SP\")\n","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":[],"sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"","interrupt":"","promptValues":"","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_1":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_1-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_1-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_1-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_1-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_1-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_1-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_1-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_1-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_1-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_1-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_1-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_1-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_1-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_1-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_1-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_1","selected":false},"width":300,"height":853,"selected":true,"positionAbsolute":{"x":2421.1700102411532,"y":-1063.1636016950542},"dragging":false},{"id":"seqEnd_1","position":{"x":2808.3128669658113,"y":-1064.117534683022},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_1.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_1","selected":false},"width":300,"height":142,"positionAbsolute":{"x":2808.3128669658113,"y":-1064.117534683022},"selected":false,"dragging":false},{"id":"chatOpenAI_1","position":{"x":3051.091885356939,"y":130.23361667429572},"type":"customNode","data":{"loadMethods":{},"label":"ChatOpenAI","name":"chatOpenAI","version":8.1,"type":"ChatOpenAI","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg","category":"Chat Models","description":"Wrapper around OpenAI large language models that use the Chat endpoint","baseClasses":["ChatOpenAI","BaseChatModel","BaseLanguageModel","Runnable"],"credential":"a0fffb09-1722-4f82-8532-e2bba4363b32","inputs":{"cache":"","modelName":"gpt-4o-mini","temperature":"0.5","streaming":true,"maxTokens":"","topP":"","frequencyPenalty":"","presencePenalty":"","timeout":"","strictToolCalling":"","stopSequence":"","basepath":"","proxyUrl":"","baseOptions":"","allowImageUploads":true,"imageResolution":"high","reasoningEffort":"low"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js","inputAnchors":[{"label":"Cache","name":"cache","type":"BaseCache","optional":true,"id":"chatOpenAI_1-input-cache-BaseCache"}],"inputParams":[{"label":"Connect Credential","name":"credential","type":"credential","credentialNames":["openAIApi"],"id":"chatOpenAI_1-input-credential-credential"},{"label":"Model Name","name":"modelName","type":"asyncOptions","loadMethod":"listModels","default":"gpt-4o-mini","id":"chatOpenAI_1-input-modelName-asyncOptions"},{"label":"Temperature","name":"temperature","type":"number","step":0.1,"default":0.9,"optional":true,"id":"chatOpenAI_1-input-temperature-number"},{"label":"Streaming","name":"streaming","type":"boolean","default":true,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-streaming-boolean"},{"label":"Max Tokens","name":"maxTokens","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-maxTokens-number"},{"label":"Top Probability","name":"topP","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-topP-number"},{"label":"Frequency Penalty","name":"frequencyPenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-frequencyPenalty-number"},{"label":"Presence Penalty","name":"presencePenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-presencePenalty-number"},{"label":"Timeout","name":"timeout","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-timeout-number"},{"label":"Strict Tool Calling","name":"strictToolCalling","type":"boolean","description":"Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-strictToolCalling-boolean"},{"label":"Stop Sequence","name":"stopSequence","type":"string","rows":4,"optional":true,"description":"List of stop words to use when generating. Use comma to separate multiple stop words.","additionalParams":true,"id":"chatOpenAI_1-input-stopSequence-string"},{"label":"BasePath","name":"basepath","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-basepath-string"},{"label":"Proxy Url","name":"proxyUrl","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-proxyUrl-string"},{"label":"BaseOptions","name":"baseOptions","type":"json","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-baseOptions-json"},{"label":"Allow Image Uploads","name":"allowImageUploads","type":"boolean","description":"Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.","default":false,"optional":true,"id":"chatOpenAI_1-input-allowImageUploads-boolean"},{"label":"Image Resolution","description":"This parameter controls the resolution in which the model views the image.","name":"imageResolution","type":"options","options":[{"label":"Low","name":"low"},{"label":"High","name":"high"},{"label":"Auto","name":"auto"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_1-input-imageResolution-options"},{"label":"Reasoning Effort","description":"Constrains effort on reasoning for reasoning models. Only applicable for o1 models","name":"reasoningEffort","type":"options","options":[{"label":"Low","name":"low"},{"label":"Medium","name":"medium"},{"label":"High","name":"high"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_1-input-reasoningEffort-options"}],"outputs":{},"outputAnchors":[{"id":"chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","name":"chatOpenAI","label":"ChatOpenAI","description":"Wrapper around OpenAI large language models that use the Chat endpoint","type":"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"}],"id":"chatOpenAI_1","selected":false},"width":300,"height":664,"selected":false,"positionAbsolute":{"x":3051.091885356939,"y":130.23361667429572},"dragging":false},{"id":"seqAgent_8","position":{"x":96.37592989409279,"y":-1422.6524024602145},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"ANALISE_CRITICA","systemMessagePrompt":"Utilize a ferramenta, observe que o chatflowId é {stepNumber}\n\n","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":["{{customTool_5.data.instance}}","{{customTool_5.data.instance}}"],"sequentialNode":["{{seqLLMNode_0.data.instance}}","{{seqLLMNode_0.data.instance}}"],"model":"","interrupt":"","promptValues":"{\"stepNumber\":\"$flow.state.criticalAnalysisStep\"}","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_8":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_8-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_8-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_8-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_8-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_8-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_8-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_8-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_8-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_8-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_8-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_8-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_8-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_8-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_8-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_8-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_8","selected":false},"width":300,"height":853,"selected":false,"positionAbsolute":{"x":96.37592989409279,"y":-1422.6524024602145},"dragging":false},{"id":"seqEnd_4","position":{"x":440.7037485480507,"y":-1425.7169732357593},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_8.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_4","selected":false},"width":300,"height":142,"positionAbsolute":{"x":440.7037485480507,"y":-1425.7169732357593},"selected":false,"dragging":false},{"id":"customTool_5","position":{"x":-301.08110683651284,"y":-1424.3555110473696},"type":"customNode","data":{"loadMethods":{},"label":"Custom Tool","name":"customTool","version":3,"type":"CustomTool","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/CustomTool/customtool.svg","category":"Tools","description":"Use custom tool you've created in Flowise within chatflow","inputs":{"selectedTool":"b84e100f-4bc8-4cc2-b2ed-d421370470b1","returnDirect":true,"customToolName":"","customToolDesc":"","customToolSchema":"","customToolFunc":""},"baseClasses":["CustomTool","Tool","StructuredTool","Runnable"],"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/CustomTool/CustomTool.js","inputAnchors":[],"inputParams":[{"label":"Select Tool","name":"selectedTool","type":"asyncOptions","loadMethod":"listTools","id":"customTool_5-input-selectedTool-asyncOptions"},{"label":"Return Direct","name":"returnDirect","description":"Return the output of the tool directly to the user","type":"boolean","optional":true,"id":"customTool_5-input-returnDirect-boolean"},{"label":"Custom Tool Name","name":"customToolName","type":"string","hidden":true,"id":"customTool_5-input-customToolName-string"},{"label":"Custom Tool Description","name":"customToolDesc","type":"string","hidden":true,"id":"customTool_5-input-customToolDesc-string"},{"label":"Custom Tool Schema","name":"customToolSchema","type":"string","hidden":true,"id":"customTool_5-input-customToolSchema-string"},{"label":"Custom Tool Func","name":"customToolFunc","type":"string","hidden":true,"id":"customTool_5-input-customToolFunc-string"}],"outputs":{},"outputAnchors":[{"id":"customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable","name":"customTool","label":"CustomTool","description":"Use custom tool you've created in Flowise within chatflow","type":"CustomTool | Tool | StructuredTool | Runnable"}],"id":"customTool_5","selected":false},"width":300,"height":369,"selected":false,"dragging":false,"positionAbsolute":{"x":-301.08110683651284,"y":-1424.3555110473696}},{"id":"seqState_0","position":{"x":-2460.3635685976947,"y":-128.19534050066954},"type":"customNode","data":{"id":"seqState_0","label":"State","version":2,"name":"seqState","type":"State","baseClasses":["State"],"category":"Sequential Agents","description":"A centralized state object, updated by nodes in the graph, passing from one node to another","inputParams":[{"label":"Custom State","name":"stateMemory","type":"tabs","tabIdentifier":"selectedStateTab","additionalParams":true,"default":"stateMemoryUI","tabs":[{"label":"Custom State (Table)","name":"stateMemoryUI","type":"datagrid","description":"Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.","hint":{"label":"How to use","value":"\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n"},"datagrid":[{"field":"key","headerName":"Key","editable":true},{"field":"type","headerName":"Operation","type":"singleSelect","valueOptions":["Replace","Append"],"editable":true},{"field":"defaultValue","headerName":"Default Value","flex":1,"editable":true}],"optional":true,"additionalParams":true},{"label":"Custom State (Code)","name":"stateMemoryCode","type":"code","description":"JSON object representing the state","hideCodeExecute":true,"codeExample":"{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}","optional":true,"additionalParams":true}],"id":"seqState_0-input-stateMemory-tabs"}],"inputAnchors":[],"inputs":{"stateMemory":"stateMemoryUI","selectedStateTab_seqState_0":"stateMemoryUI","stateMemoryUI":"[{\"key\":\"criticalAnalysisStep\",\"type\":\"Replace\",\"defaultValue\":\"null\",\"actions\":\"\",\"id\":0}]","stateMemoryCode":""},"outputAnchors":[{"id":"seqState_0-output-seqState-State","name":"seqState","label":"State","description":"A centralized state object, updated by nodes in the graph, passing from one node to another","type":"State"}],"outputs":{},"selected":false},"width":300,"height":250,"selected":false,"dragging":false,"positionAbsolute":{"x":-2460.3635685976947,"y":-128.19534050066954}},{"id":"seqLLMNode_0","position":{"x":-297.37170082791624,"y":-1016.5369201255514},"type":"customNode","data":{"label":"LLM Node","name":"seqLLMNode","version":4.1,"type":"LLMNode","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/LLMNode/llmNode.svg","category":"Sequential Agents","description":"Run Chat Model and return the output","baseClasses":["LLMNode"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-5.-llm-node","inputs":{"llmNodeName":"stepDiscover","systemMessagePrompt":"Mapear o step de análise crítica com base no número encontrado no início da última mensagem.\n    ANALISE_1: \"criticalAnalysisFirstStep\",\n    ANALISE_2: \"criticalAnalysisSecondStep\",\n    ANALISE_3: \"criticalAnalysisThirdStep\",\n    ANALISE_4: \"criticalAnalysisFourthStep\",\n    ANALISE_5: \"criticalAnalysisFifthStep\",\n    ANALISE_6: \"criticalAnalysisSixthStep\",\n    ANALISE_7: \"criticalAnalysisSeventhStep\",\nRegras:\n1. Utilizar a estrutura de mapeamento fornecida\n2. Retornar apenas a string correspondente ao step completo\n3. Usar o valor de {input} como referência inicial\nEntrada esperada: \"ANALISE_X\" (onde X é um número de 1 a 7)\nSaída esperada: String do step correspondente (exemplo: \"criticalAnalysisFirstStep\")\nCondições:\n- Sempre retornar apenas a string do step\n- Garantir que o número extraído corresponda exatamente a um dos steps mapeados\n- Caso o número não corresponda, definir um comportamento de tratamento de erro","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"","promptValues":"{\"input\":\"$flow.input\"}","llmStructuredOutput":"[]","updateStateMemory":"updateStateMemoryUI","selectedUpdateStateMemoryTab_seqLLMNode_0":"updateStateMemoryUI","updateStateMemoryUI":"[{\"value\":\"$flow.output.content\",\"actions\":\"\",\"id\":0,\"key\":\"criticalAnalysisStep\"}]"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/LLMNode/LLMNode.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this node","id":"seqLLMNode_0-input-model-BaseChatModel"}],"inputParams":[{"label":"Name","name":"llmNodeName","type":"string","placeholder":"LLM","id":"seqLLMNode_0-input-llmNodeName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqLLMNode_0-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-humanMessagePrompt-string"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"additionalParams":true,"id":"seqLLMNode_0-input-promptValues-json"},{"label":"JSON Structured Output","name":"llmStructuredOutput","type":"datagrid","description":"Instruct the LLM to give output in a JSON structured schema","datagrid":[{"field":"key","headerName":"Key","editable":true},{"field":"type","headerName":"Type","type":"singleSelect","valueOptions":["String","String Array","Number","Boolean","Enum"],"editable":true},{"field":"enumValues","headerName":"Enum Values","editable":true},{"field":"description","headerName":"Description","flex":1,"editable":true}],"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-llmStructuredOutput-datagrid"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","default":"updateStateMemoryUI","additionalParams":true,"tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"LLM Node Output (string)","value":"$flow.output.content"},{"label":"LLM JSON Output Key (string)","value":"$flow.output.<replace-with-key>"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqLLMNode_0-input-updateStateMemory-tabs"}],"outputs":{},"outputAnchors":[{"id":"seqLLMNode_0-output-seqLLMNode-LLMNode","name":"seqLLMNode","label":"LLMNode","description":"Run Chat Model and return the output","type":"LLMNode"}],"id":"seqLLMNode_0","selected":false},"width":300,"height":428,"selected":false,"positionAbsolute":{"x":-297.37170082791624,"y":-1016.5369201255514},"dragging":false}],"edges":[{"source":"chatOpenAI_0","sourceHandle":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","target":"seqStart_0","targetHandle":"seqStart_0-input-model-BaseChatModel","type":"buttonedge","id":"chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"},{"source":"chatOpenAI_1","sourceHandle":"chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","target":"seqAgent_4","targetHandle":"seqAgent_4-input-model-BaseChatModel","type":"buttonedge","id":"chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_4-seqAgent_4-input-model-BaseChatModel"},{"source":"customTool_5","sourceHandle":"customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable","target":"seqAgent_8","targetHandle":"seqAgent_8-input-tools-Tool","type":"buttonedge","id":"customTool_5-customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_8-seqAgent_8-input-tools-Tool"},{"source":"seqState_0","sourceHandle":"seqState_0-output-seqState-State","target":"seqStart_0","targetHandle":"seqStart_0-input-state-State","type":"buttonedge","id":"seqState_0-seqState_0-output-seqState-State-seqStart_0-seqStart_0-input-state-State"},{"source":"seqStart_0","sourceHandle":"seqStart_0-output-seqStart-Start","target":"seqCondition_0","targetHandle":"seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqStart_0-seqStart_0-output-seqStart-Start-seqCondition_0-seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqLLMNode_0","sourceHandle":"seqLLMNode_0-output-seqLLMNode-LLMNode","target":"seqAgent_8","targetHandle":"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqLLMNode_0-seqLLMNode_0-output-seqLLMNode-LLMNode-seqAgent_8-seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-analise_critica-Condition","target":"seqLLMNode_0","targetHandle":"seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-analise_critica-Condition-seqLLMNode_0-seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-adjustJson-Condition","target":"seqAgent_1","targetHandle":"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-adjustJson-Condition-seqAgent_1-seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_1","sourceHandle":"seqAgent_1-output-seqAgent-Agent","target":"seqEnd_1","targetHandle":"seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqEnd_1-seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-criticalAnalysis-Condition","target":"seqAgent_4","targetHandle":"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-criticalAnalysis-Condition-seqAgent_4-seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_4","sourceHandle":"seqAgent_4-output-seqAgent-Agent","target":"seqEnd_2","targetHandle":"seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_4-seqAgent_4-output-seqAgent-Agent-seqEnd_2-seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_8","sourceHandle":"seqAgent_8-output-seqAgent-Agent","target":"seqEnd_4","targetHandle":"seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_8-seqAgent_8-output-seqAgent-Agent-seqEnd_4-seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"viewport":{"x":-3839.650433247236,"y":1558.4478634699208,"zoom":2}}