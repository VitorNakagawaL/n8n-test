{"nodes":[{"id":"seqStart_0","position":{"x":-1795.2137274350782,"y":-122.40607708214543},"type":"customNode","data":{"id":"seqStart_0","label":"Start","version":2,"name":"seqStart","type":"Start","baseClasses":["Start"],"category":"Sequential Agents","description":"Starting point of the conversation","inputParams":[],"inputAnchors":[{"label":"Chat Model","name":"model","type":"BaseChatModel","description":"Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat","id":"seqStart_0-input-model-BaseChatModel"},{"label":"Agent Memory","name":"agentMemory","type":"BaseCheckpointSaver","description":"Save the state of the agent","optional":true,"id":"seqStart_0-input-agentMemory-BaseCheckpointSaver"},{"label":"State","name":"state","type":"State","description":"State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.","optional":true,"id":"seqStart_0-input-state-State"},{"label":"Input Moderation","description":"Detect text that could generate harmful output and prevent it from being sent to the language model","name":"inputModeration","type":"Moderation","optional":true,"list":true,"id":"seqStart_0-input-inputModeration-Moderation"}],"inputs":{"model":"{{chatOpenAI_0.data.instance}}","agentMemory":"","state":"{{seqState_0.data.instance}}","inputModeration":""},"outputAnchors":[{"id":"seqStart_0-output-seqStart-Start","name":"seqStart","label":"Start","description":"Starting point of the conversation","type":"Start"}],"outputs":{},"selected":false},"width":300,"height":378,"selected":false,"positionAbsolute":{"x":-1795.2137274350782,"y":-122.40607708214543},"dragging":false},{"id":"chatOpenAI_0","position":{"x":-2135.2205553499634,"y":-124.87869272872057},"type":"customNode","data":{"loadMethods":{},"label":"ChatOpenAI","name":"chatOpenAI","version":8.1,"type":"ChatOpenAI","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg","category":"Chat Models","description":"Wrapper around OpenAI large language models that use the Chat endpoint","baseClasses":["ChatOpenAI","BaseChatModel","BaseLanguageModel","Runnable"],"credential":"a0fffb09-1722-4f82-8532-e2bba4363b32","inputs":{"cache":"","modelName":"gpt-4o-mini","temperature":"0","streaming":true,"maxTokens":"","topP":"","frequencyPenalty":"","presencePenalty":"","timeout":"","strictToolCalling":"","stopSequence":"","basepath":"","proxyUrl":"","baseOptions":"","allowImageUploads":false,"imageResolution":"high","reasoningEffort":"low"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js","inputAnchors":[{"label":"Cache","name":"cache","type":"BaseCache","optional":true,"id":"chatOpenAI_0-input-cache-BaseCache"}],"inputParams":[{"label":"Connect Credential","name":"credential","type":"credential","credentialNames":["openAIApi"],"id":"chatOpenAI_0-input-credential-credential"},{"label":"Model Name","name":"modelName","type":"asyncOptions","loadMethod":"listModels","default":"gpt-4o-mini","id":"chatOpenAI_0-input-modelName-asyncOptions"},{"label":"Temperature","name":"temperature","type":"number","step":0.1,"default":0.9,"optional":true,"id":"chatOpenAI_0-input-temperature-number"},{"label":"Streaming","name":"streaming","type":"boolean","default":true,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-streaming-boolean"},{"label":"Max Tokens","name":"maxTokens","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-maxTokens-number"},{"label":"Top Probability","name":"topP","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-topP-number"},{"label":"Frequency Penalty","name":"frequencyPenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-frequencyPenalty-number"},{"label":"Presence Penalty","name":"presencePenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-presencePenalty-number"},{"label":"Timeout","name":"timeout","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-timeout-number"},{"label":"Strict Tool Calling","name":"strictToolCalling","type":"boolean","description":"Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-strictToolCalling-boolean"},{"label":"Stop Sequence","name":"stopSequence","type":"string","rows":4,"optional":true,"description":"List of stop words to use when generating. Use comma to separate multiple stop words.","additionalParams":true,"id":"chatOpenAI_0-input-stopSequence-string"},{"label":"BasePath","name":"basepath","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-basepath-string"},{"label":"Proxy Url","name":"proxyUrl","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-proxyUrl-string"},{"label":"BaseOptions","name":"baseOptions","type":"json","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-baseOptions-json"},{"label":"Allow Image Uploads","name":"allowImageUploads","type":"boolean","description":"Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.","default":false,"optional":true,"id":"chatOpenAI_0-input-allowImageUploads-boolean"},{"label":"Image Resolution","description":"This parameter controls the resolution in which the model views the image.","name":"imageResolution","type":"options","options":[{"label":"Low","name":"low"},{"label":"High","name":"high"},{"label":"Auto","name":"auto"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-imageResolution-options"},{"label":"Reasoning Effort","description":"Constrains effort on reasoning for reasoning models. Only applicable for o1 models","name":"reasoningEffort","type":"options","options":[{"label":"Low","name":"low"},{"label":"Medium","name":"medium"},{"label":"High","name":"high"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-reasoningEffort-options"}],"outputs":{},"outputAnchors":[{"id":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","name":"chatOpenAI","label":"ChatOpenAI","description":"Wrapper around OpenAI large language models that use the Chat endpoint","type":"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"}],"id":"chatOpenAI_0","selected":false},"width":300,"height":664,"selected":false,"positionAbsolute":{"x":-2135.2205553499634,"y":-124.87869272872057},"dragging":false},{"id":"seqCondition_0","position":{"x":-795.1010517858365,"y":-18.00967812176765},"type":"customNode","data":{"label":"Condition","name":"seqCondition","version":2.1,"type":"Condition","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Condition/condition.svg","category":"Sequential Agents","description":"Conditional function to determine which route to take next","baseClasses":["Condition"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-7.-conditional-node","inputs":{"conditionName":"step-identification","sequentialNode":["{{seqStart_0.data.instance}}","{{seqStart_0.data.instance}}"],"condition":"","selectedConditionFunctionTab_seqCondition_0":"conditionFunction","conditionFunction":"const messages = $flow.state.messages;\nconst lastMessage = messages[messages.length - 1];\nconst content = lastMessage.content;\n\nif (content.includes(\"CORRIGE_JSON\")) {\n  return \"Adjust JSON\";\n}\n\nif (content.startsWith(\"ANALISE_\")) {\n   return \"ANALISE_CRITICA\";\n}\n\nreturn \"Critical Analysis\";\n"},"outputs":{"output":"next"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Condition/Condition.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[{"label":"Condition Name","name":"conditionName","type":"string","optional":true,"placeholder":"If X, then Y","id":"seqCondition_0-input-conditionName-string"},{"label":"Condition","name":"condition","type":"conditionFunction","tabIdentifier":"selectedConditionFunctionTab","tabs":[{"label":"Condition (Table)","name":"conditionUI","type":"datagrid","description":"If a condition is met, the node connected to the respective output will be executed","optional":true,"datagrid":[{"field":"variable","headerName":"Variable","type":"freeSolo","editable":true,"loadMethod":["getPreviousMessages","loadStateKeys"],"valueOptions":[{"label":"Total Messages (number)","value":"$flow.state.messages.length"},{"label":"First Message Content (string)","value":"$flow.state.messages[0].content"},{"label":"Last Message Content (string)","value":"$flow.state.messages[-1].content"},{"label":"Global variable (string)","value":"$vars.<variable-name>"}],"flex":0.5,"minWidth":200},{"field":"operation","headerName":"Operation","type":"singleSelect","valueOptions":["Contains","Not Contains","Start With","End With","Is","Is Not","Is Empty","Is Not Empty","Greater Than","Less Than","Equal To","Not Equal To","Greater Than or Equal To","Less Than or Equal To"],"editable":true,"flex":0.4,"minWidth":150},{"field":"value","headerName":"Value","flex":1,"editable":true},{"field":"output","headerName":"Output Name","editable":true,"flex":0.3,"minWidth":150}]},{"label":"Condition (Code)","name":"conditionFunction","type":"code","description":"Function to evaluate the condition","hint":{"label":"How to use","value":"\n1. Must return a string value at the end of function. For example:\n    ```js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n    For example, to get the last message content:\n    ```js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    ```\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"hideCodeExecute":true,"codeExample":"const state = $flow.state;\n                \nconst messages = state.messages;\n\nconst lastMessage = messages[messages.length - 1];\n\n/* Check if the last message has content */\nif (lastMessage.content) {\n    return \"Agent\";\n}\n\nreturn \"End\";","optional":true}],"id":"seqCondition_0-input-condition-conditionFunction"}],"outputAnchors":[{"name":"output","label":"Output","type":"options","description":"","options":[{"id":"seqCondition_0-output-analise_critica-Condition","name":"analise_critica","label":"ANALISE_CRITICA","type":"Condition","isAnchor":true},{"id":"seqCondition_0-output-adjustJson-Condition","name":"adjustJson","label":"Adjust JSON","type":"Condition","isAnchor":true},{"id":"seqCondition_0-output-criticalAnalysis-Condition","name":"criticalAnalysis","label":"Critical Analysis","type":"Condition","isAnchor":true}],"default":"next"}],"id":"seqCondition_0","selected":false},"width":300,"height":520,"selected":false,"dragging":false,"positionAbsolute":{"x":-795.1010517858365,"y":-18.00967812176765}},{"id":"seqEnd_2","position":{"x":3876.422694432113,"y":120.08561088307323},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_4.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_2","selected":false},"width":300,"height":142,"positionAbsolute":{"x":3876.422694432113,"y":120.08561088307323},"selected":false,"dragging":false},{"id":"seqAgent_4","position":{"x":3450.050078158654,"y":125.8205866161706},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"critical-analysis","systemMessagePrompt":"Voc√™ atuar√° como um OCR inteligente para processar imagens e extrair dados textuais relevantes. Ser√° fornecido um plain-text contendo a pr√©-extra√ß√£o dos caracteres do documento. Sua tarefa √© estruturar essas informa√ß√µes em formato markdown, organizando chaves e valores de forma hier√°rquica, respeitando headers, tabelas e demais elementos estruturais do documento original encontrado nas imagens carregadas. Os dados extra√≠dos devem possuir alta precis√£o, garantindo que nenhuma informa√ß√£o seja adicionada ou interpretada erroneamente. Ap√≥s a extra√ß√£o, converta o markdown gerado para um JSON estruturado, preservando corretamente a rela√ß√£o entre os dados e extraindo somente as informa√ß√µes contidas no template citado abaixo, usando como fonte o documento carregado e o markdown, preencha os seguintes dados:\n  - HS Code: [...] (Pesquise chaves com os nomes \"Tariff Number\", \"Tariff No.\", \"HS Code\", \"Harmonized System Code\", \"Tariff Code\". Nunca pode ser confundido com o NCM. Se um valor for encontrado e corresponder ao NCM extra√≠do, rejeite-o e continue a busca. *N√ÉO* extraia CNPJs, CPFs, n√∫meros de telefone ou outros c√≥digos num√©ricos n√£o relacionados. Se n√£o encontrar um valor v√°lido condizente, indique \"N√£o identificado\". Exemplo: \"HS Code: 850440\" ‚Üí HS Code: \"850440\".)\n  - NCM: [ ... ] ( O valor do NCM ter√° obrigatoriamente 8 d√≠gitos num√©ricos.  Os valores devem obrigatoriamente estar pr√≥ximos √† chaves com o nome \"NCM\". Desconsidere qualquer valor que n√£o atenda os requisitos. \n  - INCOTERM: (sempre com 3 letras: EXW, FCA, FAS, FOB, CPT, CIP, CFR, CIF, DAP, DPU, DDP)\n  - Local INCOTERM: (Busque o texto imediatamente ap√≥s a sigla de um INCOTERM V√°lido (EXW, FCA, FAS, FOB, CPT, CIP, CFR, CIF, DAP, DPU, DDP). Esse texto deve representar o nome de um porto, cidade ou local de entrega e pode conter mais de uma palavra. Extraia todo o conte√∫do at√© o pr√≥ximo delimitador, como uma v√≠rgula, um ponto, ou uma quebra de linha. Exemplo: \"FOB Shanghai Port Terminal 3\" ‚Üí Local INCOTERM: \"Shanghai Port Terminal 3\".)\n  - Peso bruto estimado: (Busque por termos como \"Gross Weight\", \"Peso Bruto\", \"Poids Brut\", \"Gewicht\", \"G Weight\", seguidos de um valor num√©rico acompanhado de uma unidade v√°lida (kg, lbs, mt, etc). Se houver m√∫ltiplos valores, priorize o maior peso total indicado no documento. Exemplo: \"Gross Weight: 12,500 kg\" ‚Üí Peso bruto estimado: \"12,500 KG)\n  - M3 estimada/quantidade de volumes e dimens√µes: (Procure por \"Volume\", \"Cubic Meters\", \"CBM\", \"M¬≥\", \"Dimens√µes\", \"Quantidade de Volumes\", \"Quantidade de Caixas\", \"Quantidade de Pallets\", \"Packing\", \"Bultos\", \"Packaging\", \"cartons\", \"pallets\", \"HC\", \"NOR\", etc.  Traga o volume total estimado com sua respectiva unidade de medida ou a quantidade de volumes multiplicado pelas dimens√µes. Geralmente descreve como a mercadoria est√° comportada.\n  - Pa√≠s de origem/fabrica√ß√£o: (Busque por termos como \"Country of Origin\", \"Made in\", \"Fabricado em\", \"Origine\", \"Herkunft\", \"Product Origin\", \"Country of Provenance\" seguidos de um nome de pa√≠s.)\nPa√≠s de embarque: (Busque por termos como \"Country of Shipment\", \"Port of Loading\", \"Port Loading\", \"Pa√≠s de Embarque\", \"Lieu d'embarquement\", \"Verladehafen\", \"Pto. Emb.\", \"Ponto de embarque\" geralmente seguidos do nome de um local. Se o valor encontrado for uma cidade em vez de um pa√≠s, identifique a qual pa√≠s essa cidade pertence. Exemplo: \"Port of Loading: Hamburg\" ‚Üí Pa√≠s de Embarque: \"Alemanha\".\n  - Estado do Importador: (Busque a sigla do estado brasileiro associada ao importador, geralmente encontrada pr√≥xima a termos como \"Consignee\", \"Importer Address\", \"Endere√ßo do Importador\", \"Destinat√°rio\", \"Importador\", \"Final Destination\", \"Buyer\", \"TO:\" ou qualquer outro que indique o comprador relacionado √†quele processo. D√™ prioridade a siglas de dois caracteres que correspondam a estados do Brasil (exemplo: SP, RJ, MG, PR). Caso o estado apare√ßa por extenso, converta para a sigla correspondente. Extraia somente a sigla do estado, evitando outras informa√ß√µes no endere√ßo.)\n   - Descri√ß√£o da mercadoria: (Busque pela descri√ß√£o da mercadoria equivalente ao NCM encontrado, podendo ela estar identificada com uma label de \"descri√ß√£o\" no documento ou n√£o.)\n    - Valor da mercadoria: (Encontre o valor unit√°rio da mercadoria em quest√£o, referente ao NCM encontrado. O valor deve sempre estar identificado em uma unidade monet√°ria e deve ser referente √† unidade, n√£o ao valor total da mercadoria ou do documento como um todo.)\n\nInstru√ß√µes:\n  1. Se alguma informa√ß√£o n√£o for encontrada na imagem, traga a chave e insira o seu valor como null.\n  2. Formate a resposta final exclusivamente como um JSON de linha √∫nica, onde cada chave esteja corretamente associada ao valor correspondente.\n  3. N√£o utilize formata√ß√£o adicional, como Markdown, espa√ßos extras ou quebras de linha.\n  4. O NCM sempre ser√° um array √∫nico, NUNCA ser√° um objeto.\n5. O HS Code sempre ser√° um array √∫nico, NUNCA ser√° um objeto.\n6. **Somente** se  enfrentar algum erro e n√£o encontrar nenhuma informa√ß√£o retorne o JSON com todas chaves como null\n7. **Nunca** retorne uma mensagem de texto\n\nPara o NCM:\n- Considere que o ncm sempre ser√° um array √∫nico, ou seja, TODAS entradas ser√£o diretamente acess√≠veis, ao identificar novos NCMS apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"10203040\", \"50607080\"], se for identificado um novo NCM \"80709010\", por exemplo, ao adicionar teremos: [\"10203040\", \"50607080\", \"80709010\"]. Obs: Apenas NCMS de 8 D√çGITOS.\n\nPara o HSCODE:\n- Considere que o 'HS Code' sempre ser√° um array √∫nico, ou seja, TODAS entradas ser√£o diretamente acess√≠veis, ao identificar novos HS Codes apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo HS Code \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\nNUNCA retorne uma mensagem de texto.\n\nExemplo de resposta:\n  (\"HS Code\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"NCM\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"INCOTERM\": \"FOB\", \"Local do INCOTERM\": \"Porto\", \"Peso bruto estimado\": \"1000kg\", \"M3 estimada/quantidade de volumes e dimens√µes\": \"50m3\", \"Pa√≠s de origem/fabrica√ß√£o\": \"Brasil\", \"Pa√≠s de embarque\": \"Brasil\", \"Estado do Importador\": \"SP\")\n\nRegras de Extra√ß√£o:\n- Foque na precis√£o: Verifique se os dados extra√≠dos fazem sentido no contexto.\n- Elimine falsos positivos: Ignore ru√≠dos ou fragmentos n√£o relacionados.\n- Corrija erros comuns de OCR: Como quebras de linha indevidas, caracteres corrompidos (ex: \"1l\" para \"11\"), erros em datas e formata√ß√£o inconsistente.\nErros comuns e como lidar:\n- Texto truncado ou fragmentado: Se encontrar partes de dados quebradas, tente reconstruir com base no contexto.\n- Reconhecimento incorreto de caracteres: Exemplo: \"O00l\" pode ser \"001\" ou \"00l\". Use padr√µes comuns para validar.\n- Quebras de linha indevidas: Se um campo estiver fragmentado, reconstrua-o corretamente antes de processar.","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":"","sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"{{chatOpenAI_1.data.instance}}","interrupt":"","promptValues":"","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_4":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_4-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_4-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_4-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_4-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_4-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_4-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_4-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_4-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_4-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_4-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_4-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_4-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_4-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_4-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_4-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_4","selected":false},"width":300,"height":853,"selected":false,"positionAbsolute":{"x":3450.050078158654,"y":125.8205866161706},"dragging":false},{"id":"seqAgent_1","position":{"x":2421.1700102411532,"y":-1063.1636016950542},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"adjust-json","systemMessagePrompt":"Voc√™ receber√° um json e um texto.\n\n  - Traga APENAS os seguintes dados encontrados no texto(Esses nomes podem estar em outro idioma, ou com nomes semelhantes):\n  - HS Code: [...] (Pesquise chaves com o nome como \"Tariff Number\", \"Tariff No.\", \"HS Code\") \n  - NCM: [ ... ] (Pesquise apenas chaves com o nome NCM)\n  - INCOTERM e Local\n  - Peso bruto estimado\n  - M3 estimada/quantidade de volumes e dimens√µes\n  - Pa√≠s de origem/fabrica√ß√£o\n  - Pa√≠s de embarque\n  - Estado do Importador\n  - Descri√ß√£o da mercadoria\n  - Valor da mercadoria\n\n- Mude no os campos no JSON recebido APENAS os dados que forem encontrados no texto.\n\n- Sempre formate a resposta final em um JSON de linha √∫nica para correlacionar as chaves e valores. Nunca utilize formata√ß√£o Markdown. Certifique-se de que n√£o haja espa√ßos ou quebras de linha entre os elementos do objeto na resposta final.\n\n- Caso n√£o encontre algum dos dados retorne o valor da chave como null.\n\n- SEMPRE retorne um JSON, NUNCA escreva uma mensagem\n\n- O NCM sempre ser√° um array √∫nico, NUNCA ser√° um objeto.\n\n- O HS Code sempre ser√° um array √∫nico, NUNCA ser√° um objeto.\n\n- Considere que o ncm sempre ser√° um array √∫nico, ou seja, TODAS entradas ser√£o diretamente acess√≠veis, ao identificar novos NCMS apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo NCM \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\n- Considere que o HS Code sempre ser√° um array √∫nico, ou seja, TODAS entradas ser√£o diretamente acess√≠veis, ao identificar novos HS Codes apenas adicione a nova entrada no array. Deve ser diretamente um array de strings. Ex: [\"102030\", \"506070\"], se for identificado um novo HS Code \"807090\", por exemplo, ao adicionar teremos: [\"102030\", \"506070\", \"807090\"].\n\nExemplo de resposta:\n  (\"HS Code\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"NCM\": [\"XXXXXXXX\", \"YYYYYYYY\"], \"INCOTERM\": \"FOB\", \"Local do INCOTERM\": \"Porto\", \"Peso bruto estimado\": \"1000kg\", \"M3 estimada/quantidade de volumes e dimens√µes\": \"50m3\", \"Pa√≠s de origem/fabrica√ß√£o\": \"Brasil\", \"Pa√≠s de embarque\": \"Brasil\", \"Estado do Importador\": \"SP\")\n","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":[],"sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"","interrupt":"","promptValues":"","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_1":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_1-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_1-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_1-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_1-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_1-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_1-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_1-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_1-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_1-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_1-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_1-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_1-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_1-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_1-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_1-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_1","selected":false},"width":300,"height":853,"selected":true,"positionAbsolute":{"x":2421.1700102411532,"y":-1063.1636016950542},"dragging":false},{"id":"seqEnd_1","position":{"x":2808.3128669658113,"y":-1064.117534683022},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_1.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_1","selected":false},"width":300,"height":142,"positionAbsolute":{"x":2808.3128669658113,"y":-1064.117534683022},"selected":false,"dragging":false},{"id":"chatOpenAI_1","position":{"x":3051.091885356939,"y":130.23361667429572},"type":"customNode","data":{"loadMethods":{},"label":"ChatOpenAI","name":"chatOpenAI","version":8.1,"type":"ChatOpenAI","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg","category":"Chat Models","description":"Wrapper around OpenAI large language models that use the Chat endpoint","baseClasses":["ChatOpenAI","BaseChatModel","BaseLanguageModel","Runnable"],"credential":"a0fffb09-1722-4f82-8532-e2bba4363b32","inputs":{"cache":"","modelName":"gpt-4o-mini","temperature":"0.5","streaming":true,"maxTokens":"","topP":"","frequencyPenalty":"","presencePenalty":"","timeout":"","strictToolCalling":"","stopSequence":"","basepath":"","proxyUrl":"","baseOptions":"","allowImageUploads":true,"imageResolution":"high","reasoningEffort":"low"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js","inputAnchors":[{"label":"Cache","name":"cache","type":"BaseCache","optional":true,"id":"chatOpenAI_1-input-cache-BaseCache"}],"inputParams":[{"label":"Connect Credential","name":"credential","type":"credential","credentialNames":["openAIApi"],"id":"chatOpenAI_1-input-credential-credential"},{"label":"Model Name","name":"modelName","type":"asyncOptions","loadMethod":"listModels","default":"gpt-4o-mini","id":"chatOpenAI_1-input-modelName-asyncOptions"},{"label":"Temperature","name":"temperature","type":"number","step":0.1,"default":0.9,"optional":true,"id":"chatOpenAI_1-input-temperature-number"},{"label":"Streaming","name":"streaming","type":"boolean","default":true,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-streaming-boolean"},{"label":"Max Tokens","name":"maxTokens","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-maxTokens-number"},{"label":"Top Probability","name":"topP","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-topP-number"},{"label":"Frequency Penalty","name":"frequencyPenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-frequencyPenalty-number"},{"label":"Presence Penalty","name":"presencePenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-presencePenalty-number"},{"label":"Timeout","name":"timeout","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-timeout-number"},{"label":"Strict Tool Calling","name":"strictToolCalling","type":"boolean","description":"Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-strictToolCalling-boolean"},{"label":"Stop Sequence","name":"stopSequence","type":"string","rows":4,"optional":true,"description":"List of stop words to use when generating. Use comma to separate multiple stop words.","additionalParams":true,"id":"chatOpenAI_1-input-stopSequence-string"},{"label":"BasePath","name":"basepath","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-basepath-string"},{"label":"Proxy Url","name":"proxyUrl","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-proxyUrl-string"},{"label":"BaseOptions","name":"baseOptions","type":"json","optional":true,"additionalParams":true,"id":"chatOpenAI_1-input-baseOptions-json"},{"label":"Allow Image Uploads","name":"allowImageUploads","type":"boolean","description":"Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.","default":false,"optional":true,"id":"chatOpenAI_1-input-allowImageUploads-boolean"},{"label":"Image Resolution","description":"This parameter controls the resolution in which the model views the image.","name":"imageResolution","type":"options","options":[{"label":"Low","name":"low"},{"label":"High","name":"high"},{"label":"Auto","name":"auto"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_1-input-imageResolution-options"},{"label":"Reasoning Effort","description":"Constrains effort on reasoning for reasoning models. Only applicable for o1 models","name":"reasoningEffort","type":"options","options":[{"label":"Low","name":"low"},{"label":"Medium","name":"medium"},{"label":"High","name":"high"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_1-input-reasoningEffort-options"}],"outputs":{},"outputAnchors":[{"id":"chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","name":"chatOpenAI","label":"ChatOpenAI","description":"Wrapper around OpenAI large language models that use the Chat endpoint","type":"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"}],"id":"chatOpenAI_1","selected":false},"width":300,"height":664,"selected":false,"positionAbsolute":{"x":3051.091885356939,"y":130.23361667429572},"dragging":false},{"id":"seqAgent_8","position":{"x":96.37592989409279,"y":-1422.6524024602145},"type":"customNode","data":{"label":"Agent","name":"seqAgent","version":4.1,"type":"Agent","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/seqAgent.png","category":"Sequential Agents","description":"Agent that can execute tools","baseClasses":["Agent"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-4.-agent-node","inputs":{"agentName":"ANALISE_CRITICA","systemMessagePrompt":"Utilize a ferramenta, observe que o chatflowId √© {stepNumber}\n\n","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","tools":["{{customTool_5.data.instance}}","{{customTool_5.data.instance}}"],"sequentialNode":["{{seqLLMNode_0.data.instance}}","{{seqLLMNode_0.data.instance}}"],"model":"","interrupt":"","promptValues":"{\"stepNumber\":\"$flow.state.criticalAnalysisStep\"}","approvalPrompt":"You are about to execute tool: {tools}. Ask if user want to proceed","approveButtonText":"Yes","rejectButtonText":"No","updateStateMemory":"updateStateMemoryUI","maxIterations":"","selectedUpdateStateMemoryTab_seqAgent_8":"updateStateMemoryUI"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/Agent/Agent.js","inputAnchors":[{"label":"Tools","name":"tools","type":"Tool","list":true,"optional":true,"id":"seqAgent_8-input-tools-Tool"},{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this agent","id":"seqAgent_8-input-model-BaseChatModel"}],"inputParams":[{"label":"Agent Name","name":"agentName","type":"string","placeholder":"Agent","id":"seqAgent_8-input-agentName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"default":"You are a research assistant who can search for up-to-date info using search engine.","id":"seqAgent_8-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqAgent_8-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqAgent_8-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_8-input-humanMessagePrompt-string"},{"label":"Require Approval","name":"interrupt","description":"Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.","type":"boolean","optional":true,"id":"seqAgent_8-input-interrupt-boolean"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"id":"seqAgent_8-input-promptValues-json"},{"label":"Approval Prompt","name":"approvalPrompt","description":"Prompt for approval. Only applicable if \"Require Approval\" is enabled","type":"string","default":"You are about to execute tool: {tools}. Ask if user want to proceed","rows":4,"optional":true,"additionalParams":true,"id":"seqAgent_8-input-approvalPrompt-string"},{"label":"Approve Button Text","name":"approveButtonText","description":"Text for approve button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"Yes","optional":true,"additionalParams":true,"id":"seqAgent_8-input-approveButtonText-string"},{"label":"Reject Button Text","name":"rejectButtonText","description":"Text for reject button. Only applicable if \"Require Approval\" is enabled","type":"string","default":"No","optional":true,"additionalParams":true,"id":"seqAgent_8-input-rejectButtonText-string"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","additionalParams":true,"default":"updateStateMemoryUI","tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"Agent Output (string)","value":"$flow.output.content"},{"label":"Used Tools (array)","value":"$flow.output.usedTools"},{"label":"First Tool Output (string)","value":"$flow.output.usedTools[0].toolOutput"},{"label":"Source Documents (array)","value":"$flow.output.sourceDocuments"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqAgent_8-input-updateStateMemory-tabs"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"seqAgent_8-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"seqAgent_8-output-seqAgent-Agent","name":"seqAgent","label":"Agent","description":"Agent that can execute tools","type":"Agent"}],"id":"seqAgent_8","selected":false},"width":300,"height":853,"selected":false,"positionAbsolute":{"x":96.37592989409279,"y":-1422.6524024602145},"dragging":false},{"id":"seqEnd_4","position":{"x":440.7037485480507,"y":-1425.7169732357593},"type":"customNode","data":{"label":"End","name":"seqEnd","version":2.1,"type":"End","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/end.svg","category":"Sequential Agents","description":"End conversation","baseClasses":["End"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node","inputs":{"sequentialNode":"{{seqAgent_8.data.instance}}"},"hideOutput":true,"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/End/End.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow","id":"seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"inputParams":[],"outputs":{},"outputAnchors":[],"id":"seqEnd_4","selected":false},"width":300,"height":142,"positionAbsolute":{"x":440.7037485480507,"y":-1425.7169732357593},"selected":false,"dragging":false},{"id":"customTool_5","position":{"x":-301.08110683651284,"y":-1424.3555110473696},"type":"customNode","data":{"loadMethods":{},"label":"Custom Tool","name":"customTool","version":3,"type":"CustomTool","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/CustomTool/customtool.svg","category":"Tools","description":"Use custom tool you've created in Flowise within chatflow","inputs":{"selectedTool":"b84e100f-4bc8-4cc2-b2ed-d421370470b1","returnDirect":true,"customToolName":"","customToolDesc":"","customToolSchema":"","customToolFunc":""},"baseClasses":["CustomTool","Tool","StructuredTool","Runnable"],"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/CustomTool/CustomTool.js","inputAnchors":[],"inputParams":[{"label":"Select Tool","name":"selectedTool","type":"asyncOptions","loadMethod":"listTools","id":"customTool_5-input-selectedTool-asyncOptions"},{"label":"Return Direct","name":"returnDirect","description":"Return the output of the tool directly to the user","type":"boolean","optional":true,"id":"customTool_5-input-returnDirect-boolean"},{"label":"Custom Tool Name","name":"customToolName","type":"string","hidden":true,"id":"customTool_5-input-customToolName-string"},{"label":"Custom Tool Description","name":"customToolDesc","type":"string","hidden":true,"id":"customTool_5-input-customToolDesc-string"},{"label":"Custom Tool Schema","name":"customToolSchema","type":"string","hidden":true,"id":"customTool_5-input-customToolSchema-string"},{"label":"Custom Tool Func","name":"customToolFunc","type":"string","hidden":true,"id":"customTool_5-input-customToolFunc-string"}],"outputs":{},"outputAnchors":[{"id":"customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable","name":"customTool","label":"CustomTool","description":"Use custom tool you've created in Flowise within chatflow","type":"CustomTool | Tool | StructuredTool | Runnable"}],"id":"customTool_5","selected":false},"width":300,"height":369,"selected":false,"dragging":false,"positionAbsolute":{"x":-301.08110683651284,"y":-1424.3555110473696}},{"id":"seqState_0","position":{"x":-2460.3635685976947,"y":-128.19534050066954},"type":"customNode","data":{"id":"seqState_0","label":"State","version":2,"name":"seqState","type":"State","baseClasses":["State"],"category":"Sequential Agents","description":"A centralized state object, updated by nodes in the graph, passing from one node to another","inputParams":[{"label":"Custom State","name":"stateMemory","type":"tabs","tabIdentifier":"selectedStateTab","additionalParams":true,"default":"stateMemoryUI","tabs":[{"label":"Custom State (Table)","name":"stateMemoryUI","type":"datagrid","description":"Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.","hint":{"label":"How to use","value":"\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n"},"datagrid":[{"field":"key","headerName":"Key","editable":true},{"field":"type","headerName":"Operation","type":"singleSelect","valueOptions":["Replace","Append"],"editable":true},{"field":"defaultValue","headerName":"Default Value","flex":1,"editable":true}],"optional":true,"additionalParams":true},{"label":"Custom State (Code)","name":"stateMemoryCode","type":"code","description":"JSON object representing the state","hideCodeExecute":true,"codeExample":"{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}","optional":true,"additionalParams":true}],"id":"seqState_0-input-stateMemory-tabs"}],"inputAnchors":[],"inputs":{"stateMemory":"stateMemoryUI","selectedStateTab_seqState_0":"stateMemoryUI","stateMemoryUI":"[{\"key\":\"criticalAnalysisStep\",\"type\":\"Replace\",\"defaultValue\":\"null\",\"actions\":\"\",\"id\":0}]","stateMemoryCode":""},"outputAnchors":[{"id":"seqState_0-output-seqState-State","name":"seqState","label":"State","description":"A centralized state object, updated by nodes in the graph, passing from one node to another","type":"State"}],"outputs":{},"selected":false},"width":300,"height":250,"selected":false,"dragging":false,"positionAbsolute":{"x":-2460.3635685976947,"y":-128.19534050066954}},{"id":"seqLLMNode_0","position":{"x":-297.37170082791624,"y":-1016.5369201255514},"type":"customNode","data":{"label":"LLM Node","name":"seqLLMNode","version":4.1,"type":"LLMNode","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/LLMNode/llmNode.svg","category":"Sequential Agents","description":"Run Chat Model and return the output","baseClasses":["LLMNode"],"documentation":"https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-5.-llm-node","inputs":{"llmNodeName":"stepDiscover","systemMessagePrompt":"Mapear o step de an√°lise cr√≠tica com base no n√∫mero encontrado no in√≠cio da √∫ltima mensagem.\n    ANALISE_1: \"criticalAnalysisFirstStep\",\n    ANALISE_2: \"criticalAnalysisSecondStep\",\n    ANALISE_3: \"criticalAnalysisThirdStep\",\n    ANALISE_4: \"criticalAnalysisFourthStep\",\n    ANALISE_5: \"criticalAnalysisFifthStep\",\n    ANALISE_6: \"criticalAnalysisSixthStep\",\n    ANALISE_7: \"criticalAnalysisSeventhStep\",\nRegras:\n1. Utilizar a estrutura de mapeamento fornecida\n2. Retornar apenas a string correspondente ao step completo\n3. Usar o valor de {input} como refer√™ncia inicial\nEntrada esperada: \"ANALISE_X\" (onde X √© um n√∫mero de 1 a 7)\nSa√≠da esperada: String do step correspondente (exemplo: \"criticalAnalysisFirstStep\")\nCondi√ß√µes:\n- Sempre retornar apenas a string do step\n- Garantir que o n√∫mero extra√≠do corresponda exatamente a um dos steps mapeados\n- Caso o n√∫mero n√£o corresponda, definir um comportamento de tratamento de erro","messageHistory":"","conversationHistorySelection":"all_messages","humanMessagePrompt":"","sequentialNode":["{{seqCondition_0.data.instance}}","{{seqCondition_0.data.instance}}"],"model":"","promptValues":"{\"input\":\"$flow.input\"}","llmStructuredOutput":"[]","updateStateMemory":"updateStateMemoryUI","selectedUpdateStateMemoryTab_seqLLMNode_0":"updateStateMemoryUI","updateStateMemoryUI":"[{\"value\":\"$flow.output.content\",\"actions\":\"\",\"id\":0,\"key\":\"criticalAnalysisStep\"}]"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/sequentialagents/LLMNode/LLMNode.js","inputAnchors":[{"label":"Sequential Node","name":"sequentialNode","type":"Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","description":"Can be connected to one of the following nodes: Start, Agent, Condition, LLM, Tool Node, Custom Function, Execute Flow","list":true,"id":"seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"label":"Chat Model","name":"model","type":"BaseChatModel","optional":true,"description":"Overwrite model to be used for this node","id":"seqLLMNode_0-input-model-BaseChatModel"}],"inputParams":[{"label":"Name","name":"llmNodeName","type":"string","placeholder":"LLM","id":"seqLLMNode_0-input-llmNodeName-string"},{"label":"System Prompt","name":"systemMessagePrompt","type":"string","rows":4,"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-systemMessagePrompt-string"},{"label":"Prepend Messages History","name":"messageHistory","description":"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples","type":"code","hideCodeExecute":true,"codeExample":"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]","optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-messageHistory-code"},{"label":"Conversation History","name":"conversationHistorySelection","type":"options","options":[{"label":"User Question","name":"user_question","description":"Use the user question from the historical conversation messages as input."},{"label":"Last Conversation Message","name":"last_message","description":"Use the last conversation message from the historical conversation messages as input."},{"label":"All Conversation Messages","name":"all_messages","description":"Use all conversation messages from the historical conversation messages as input."},{"label":"Empty","name":"empty","description":"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."}],"default":"all_messages","optional":true,"description":"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].","additionalParams":true,"id":"seqLLMNode_0-input-conversationHistorySelection-options"},{"label":"Human Prompt","name":"humanMessagePrompt","type":"string","description":"This prompt will be added at the end of the messages as human message","rows":4,"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-humanMessagePrompt-string"},{"label":"Format Prompt Values","name":"promptValues","description":"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value","type":"json","optional":true,"acceptVariable":true,"list":true,"additionalParams":true,"id":"seqLLMNode_0-input-promptValues-json"},{"label":"JSON Structured Output","name":"llmStructuredOutput","type":"datagrid","description":"Instruct the LLM to give output in a JSON structured schema","datagrid":[{"field":"key","headerName":"Key","editable":true},{"field":"type","headerName":"Type","type":"singleSelect","valueOptions":["String","String Array","Number","Boolean","Enum"],"editable":true},{"field":"enumValues","headerName":"Enum Values","editable":true},{"field":"description","headerName":"Description","flex":1,"editable":true}],"optional":true,"additionalParams":true,"id":"seqLLMNode_0-input-llmStructuredOutput-datagrid"},{"label":"Update State","name":"updateStateMemory","type":"tabs","tabIdentifier":"selectedUpdateStateMemoryTab","default":"updateStateMemoryUI","additionalParams":true,"tabs":[{"label":"Update State (Table)","name":"updateStateMemoryUI","type":"datagrid","hint":{"label":"How to use","value":"\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values","datagrid":[{"field":"key","headerName":"Key","type":"asyncSingleSelect","loadMethod":"loadStateKeys","flex":0.5,"editable":true},{"field":"value","headerName":"Value","type":"freeSolo","valueOptions":[{"label":"LLM Node Output (string)","value":"$flow.output.content"},{"label":"LLM JSON Output Key (string)","value":"$flow.output.<replace-with-key>"},{"label":"Global variable (string)","value":"$vars.<variable-name>"},{"label":"Input Question (string)","value":"$flow.input"},{"label":"Session Id (string)","value":"$flow.sessionId"},{"label":"Chat Id (string)","value":"$flow.chatId"},{"label":"Chatflow Id (string)","value":"$flow.chatflowId"}],"editable":true,"flex":1}],"optional":true,"additionalParams":true},{"label":"Update State (Code)","name":"updateStateMemoryCode","type":"code","hint":{"label":"How to use","value":"\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"},"description":"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state","hideCodeExecute":true,"codeExample":"const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};","optional":true,"additionalParams":true}],"id":"seqLLMNode_0-input-updateStateMemory-tabs"}],"outputs":{},"outputAnchors":[{"id":"seqLLMNode_0-output-seqLLMNode-LLMNode","name":"seqLLMNode","label":"LLMNode","description":"Run Chat Model and return the output","type":"LLMNode"}],"id":"seqLLMNode_0","selected":false},"width":300,"height":428,"selected":false,"positionAbsolute":{"x":-297.37170082791624,"y":-1016.5369201255514},"dragging":false}],"edges":[{"source":"chatOpenAI_0","sourceHandle":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","target":"seqStart_0","targetHandle":"seqStart_0-input-model-BaseChatModel","type":"buttonedge","id":"chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"},{"source":"chatOpenAI_1","sourceHandle":"chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","target":"seqAgent_4","targetHandle":"seqAgent_4-input-model-BaseChatModel","type":"buttonedge","id":"chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_4-seqAgent_4-input-model-BaseChatModel"},{"source":"customTool_5","sourceHandle":"customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable","target":"seqAgent_8","targetHandle":"seqAgent_8-input-tools-Tool","type":"buttonedge","id":"customTool_5-customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_8-seqAgent_8-input-tools-Tool"},{"source":"seqState_0","sourceHandle":"seqState_0-output-seqState-State","target":"seqStart_0","targetHandle":"seqStart_0-input-state-State","type":"buttonedge","id":"seqState_0-seqState_0-output-seqState-State-seqStart_0-seqStart_0-input-state-State"},{"source":"seqStart_0","sourceHandle":"seqStart_0-output-seqStart-Start","target":"seqCondition_0","targetHandle":"seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqStart_0-seqStart_0-output-seqStart-Start-seqCondition_0-seqCondition_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqLLMNode_0","sourceHandle":"seqLLMNode_0-output-seqLLMNode-LLMNode","target":"seqAgent_8","targetHandle":"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqLLMNode_0-seqLLMNode_0-output-seqLLMNode-LLMNode-seqAgent_8-seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-analise_critica-Condition","target":"seqLLMNode_0","targetHandle":"seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-analise_critica-Condition-seqLLMNode_0-seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-adjustJson-Condition","target":"seqAgent_1","targetHandle":"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-adjustJson-Condition-seqAgent_1-seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_1","sourceHandle":"seqAgent_1-output-seqAgent-Agent","target":"seqEnd_1","targetHandle":"seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqEnd_1-seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqCondition_0","sourceHandle":"seqCondition_0-output-criticalAnalysis-Condition","target":"seqAgent_4","targetHandle":"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqCondition_0-seqCondition_0-output-criticalAnalysis-Condition-seqAgent_4-seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_4","sourceHandle":"seqAgent_4-output-seqAgent-Agent","target":"seqEnd_2","targetHandle":"seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_4-seqAgent_4-output-seqAgent-Agent-seqEnd_2-seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"},{"source":"seqAgent_8","sourceHandle":"seqAgent_8-output-seqAgent-Agent","target":"seqEnd_4","targetHandle":"seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow","type":"buttonedge","id":"seqAgent_8-seqAgent_8-output-seqAgent-Agent-seqEnd_4-seqEnd_4-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"}],"viewport":{"x":-3839.650433247236,"y":1558.4478634699208,"zoom":2}}