{"nodes":[{"id":"chatOpenAI_0","position":{"x":891.9108156677348,"y":-1476.1644637019504},"type":"customNode","data":{"loadMethods":{},"label":"ChatOpenAI","name":"chatOpenAI","version":8.1,"type":"ChatOpenAI","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg","category":"Chat Models","description":"Wrapper around OpenAI large language models that use the Chat endpoint","baseClasses":["ChatOpenAI","BaseChatModel","BaseLanguageModel","Runnable"],"credential":"a0fffb09-1722-4f82-8532-e2bba4363b32","inputs":{"cache":"","modelName":"gpt-4o-mini","temperature":"0.3","streaming":true,"maxTokens":"","topP":"","frequencyPenalty":"","presencePenalty":"","timeout":"","strictToolCalling":"","stopSequence":"","basepath":"","proxyUrl":"","baseOptions":"","allowImageUploads":false,"imageResolution":"low","reasoningEffort":"low"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js","inputAnchors":[{"label":"Cache","name":"cache","type":"BaseCache","optional":true,"id":"chatOpenAI_0-input-cache-BaseCache"}],"inputParams":[{"label":"Connect Credential","name":"credential","type":"credential","credentialNames":["openAIApi"],"id":"chatOpenAI_0-input-credential-credential"},{"label":"Model Name","name":"modelName","type":"asyncOptions","loadMethod":"listModels","default":"gpt-4o-mini","id":"chatOpenAI_0-input-modelName-asyncOptions"},{"label":"Temperature","name":"temperature","type":"number","step":0.1,"default":0.9,"optional":true,"id":"chatOpenAI_0-input-temperature-number"},{"label":"Streaming","name":"streaming","type":"boolean","default":true,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-streaming-boolean"},{"label":"Max Tokens","name":"maxTokens","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-maxTokens-number"},{"label":"Top Probability","name":"topP","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-topP-number"},{"label":"Frequency Penalty","name":"frequencyPenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-frequencyPenalty-number"},{"label":"Presence Penalty","name":"presencePenalty","type":"number","step":0.1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-presencePenalty-number"},{"label":"Timeout","name":"timeout","type":"number","step":1,"optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-timeout-number"},{"label":"Strict Tool Calling","name":"strictToolCalling","type":"boolean","description":"Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-strictToolCalling-boolean"},{"label":"Stop Sequence","name":"stopSequence","type":"string","rows":4,"optional":true,"description":"List of stop words to use when generating. Use comma to separate multiple stop words.","additionalParams":true,"id":"chatOpenAI_0-input-stopSequence-string"},{"label":"BasePath","name":"basepath","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-basepath-string"},{"label":"Proxy Url","name":"proxyUrl","type":"string","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-proxyUrl-string"},{"label":"BaseOptions","name":"baseOptions","type":"json","optional":true,"additionalParams":true,"id":"chatOpenAI_0-input-baseOptions-json"},{"label":"Allow Image Uploads","name":"allowImageUploads","type":"boolean","description":"Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.","default":false,"optional":true,"id":"chatOpenAI_0-input-allowImageUploads-boolean"},{"label":"Image Resolution","description":"This parameter controls the resolution in which the model views the image.","name":"imageResolution","type":"options","options":[{"label":"Low","name":"low"},{"label":"High","name":"high"},{"label":"Auto","name":"auto"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-imageResolution-options"},{"label":"Reasoning Effort","description":"Constrains effort on reasoning for reasoning models. Only applicable for o1 models","name":"reasoningEffort","type":"options","options":[{"label":"Low","name":"low"},{"label":"Medium","name":"medium"},{"label":"High","name":"high"}],"default":"low","optional":false,"additionalParams":true,"id":"chatOpenAI_0-input-reasoningEffort-options"}],"outputs":{},"outputAnchors":[{"id":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","name":"chatOpenAI","label":"ChatOpenAI","description":"Wrapper around OpenAI large language models that use the Chat endpoint","type":"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"}],"id":"chatOpenAI_0","selected":false},"width":300,"height":670,"selected":false,"positionAbsolute":{"x":891.9108156677348,"y":-1476.1644637019504},"dragging":false},{"id":"conversationalAgent_0","position":{"x":1403.3010943710588,"y":-1105.4779717197387},"type":"customNode","data":{"label":"Conversational Agent","name":"conversationalAgent","version":3,"type":"AgentExecutor","category":"Agents","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/agents/ConversationalAgent/agent.svg","description":"Conversational agent for a chat model. It will utilize chat specific prompts","baseClasses":["AgentExecutor","BaseChain","Runnable"],"inputs":{"tools":["{{calculator_0.data.instance}}"],"model":"{{chatOpenAI_0.data.instance}}","memory":"{{bufferMemory_0.data.instance}}","systemMessage":"Você é uma IA especializada em **logística e comércio exterior**, com expertise na determinação do modal de transporte internacional ideal para importações destinadas ao Brasil. Sua missão é analisar os dados fornecidos e recomendar a melhor opção dentre os seguintes modais:\n\n- **Rodoviário Internacional** (somente para a América do Sul)\n- **Aéreo Internacional**\n- **Marítimo (FCL ou LCL)**\n\nAdicionalmente, indique os serviços necessários com base no **INCOTERM** informado.\n\n---\n\n## Critérios de Análise\n\n### 1. Características da Carga\n- **Descrição da mercadoria:** Identifique requisitos especiais (ex.: perecível, perigosa, regulada, frágil, de alto valor ou sensível ao tempo).\n- **Valor da mercadoria:** Leve em conta a segurança, viabilidade e custo-benefício do modal.\n- **Peso bruto estimado (kg):** Verifique a compatibilidade com os modais.\n- **Metragem cúbica e dimensões (m³):** Analise possíveis restrições ou vantagens logísticas.\n\n### 2. Localização e Rotas\n- **País de origem:** Considere a distância, as principais rotas e os modais disponíveis.\n- **Estado do importador (UF) no Brasil:** Avalie a viabilidade do transporte rodoviário internacional, quando aplicável.\n\n### 3. INCOTERM e Responsabilidades\n- Determine o ponto de transferência de custos e riscos.\n- Liste os serviços a serem contratados conforme o INCOTERM (ex.: frete, seguro, desembaraço, etc.).\n\n---\n\n## Regras para Seleção do Modal\n\n### 1. Modal Rodoviário Internacional\n- **Aplicável somente para importações na América do Sul.**\n- Priorize se a origem e o destino permitirem transporte terrestre.\n- Recomendado para cargas de pequeno a médio porte, se viável.\n- **Limitações:**  \n  - Se o peso exceder **25 toneladas** ou o volume for superior a **70 m³**, descarte o rodoviário e priorize o marítimo (FCL).\n- Se a origem NÃO for na América do Sul, descarte automaticamente este modal.\n\n### 2. Modal Aéreo Internacional\n- **Aplicável somente para países fora da América do Sul.**\n- Indicado para cargas leves, compactas, urgentes, de alto valor ou frágeis.\n- **Critérios de recomendação:**  \n  - **Até 500 kg e até 10 m³:** Altamente recomendado.  \n  - **De 500 kg a 2.500 kg / 10 a 15 m³:** Possível, porém com custo elevado.  \n  - **Acima de 2.500 kg ou 15-20 m³:** Utilizar apenas em casos de extrema urgência.\n- Se a origem for na América do Sul, descarte automaticamente este modal.\n\n### 3. Modal Marítimo Internacional\n\n#### FCL (Full Container Load) – Contêiner Exclusivo:\n- Utilize sempre que a carga exceder um dos seguintes critérios:\n  - **Mais de 15 m³** ou\n  - **Mais de 10 toneladas**.\n- Se o peso for superior a 25 toneladas ou o volume maior que 70 m³, o FCL é obrigatório.\n- **Exceção para a América do Sul:**  \n  - Se a carga exceder 25 toneladas ou 70 m³, o modal correto é o Marítimo FCL.\n\n#### LCL (Less than Container Load):\n- Indicado para cargas com:\n  - Volume menor ou igual a 15 m³ e\n  - Peso menor ou igual a 10 toneladas.\n- Mesmo que o peso cubado seja elevado, se a carga for pequena, opte pelo LCL.\n\n---\n\n## Regras Gerais\n- **A resposta deve ser formatada exclusivamente em HTML Puro, seguindo o modelo especificado. Em nenhuma hipótese JSON deve ser incluído na resposta.**\n- Se o modelo gerar JSON como resposta, ignore esse formato e reescreva a resposta no formato HTML especificado.\n- Não inclua JSON, código ou qualquer outro formato estruturado de dados na resposta. Apenas utilize HTML puro.\n- Justifique sempre a escolha do modal com base em **custo-benefício, tempo de transporte, viabilidade operacional e regulamentos**.\n- Se possível, sugira um modal alternativo.\n- Se a origem for um país da América do Sul e a carga permitir, priorize o Rodoviário Internacional.\n- Se a origem for de fora da América do Sul, descarte automaticamente o Rodoviário e priorize o Aéreo ou Marítimo.\n- Inclua a observação padrão: *\"A análise não considera a urgência da mercadoria.\"*\n- Utilize o cálculo de peso cubado quando necessário:  \n  **Peso cubado = M³ x 166,66.**\n\n---\n\n## **Formato de Resposta**  \nA resposta deve ser SEMPRE gerada no seguinte formato **HTML Puro**:\n\n<html>\n<body>\n  <div>\n    <strong>Modal de Transporte Ideal:</strong>\n    <p>{{Modal_de_Transporte_Ideal}}</p>\n    <strong>Cálculo do Peso Cubado:</strong>\n    <p>Peso cubado = {{M3_estimada}} m³ x 166,66 = {{Peso_cubado}} kg.<br>{{descrição}}</p>\n    <strong>Serviços Necessários de Acordo com o INCOTERM {{INCOTERM}}:</strong>\n    <p>{{Serviços_Necessários}}</p>\n    <span style=\"color: red;\"><i>Observação:</i> A análise não considera a urgência da mercadoria.</span>\n  </div>\n</body>\n</html>\n\nSe a resposta contiver qualquer JSON ou outro formato que não seja HTML, refaça a resposta seguindo estritamente o formato HTML especificado.","inputModeration":"","maxIterations":""},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/agents/ConversationalAgent/ConversationalAgent.js","inputAnchors":[{"label":"Allowed Tools","name":"tools","type":"Tool","list":true,"id":"conversationalAgent_0-input-tools-Tool"},{"label":"Chat Model","name":"model","type":"BaseChatModel","id":"conversationalAgent_0-input-model-BaseChatModel"},{"label":"Memory","name":"memory","type":"BaseChatMemory","id":"conversationalAgent_0-input-memory-BaseChatMemory"},{"label":"Input Moderation","description":"Detect text that could generate harmful output and prevent it from being sent to the language model","name":"inputModeration","type":"Moderation","optional":true,"list":true,"id":"conversationalAgent_0-input-inputModeration-Moderation"}],"inputParams":[{"label":"System Message","name":"systemMessage","type":"string","rows":4,"default":"Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.","optional":true,"additionalParams":true,"id":"conversationalAgent_0-input-systemMessage-string"},{"label":"Max Iterations","name":"maxIterations","type":"number","optional":true,"additionalParams":true,"id":"conversationalAgent_0-input-maxIterations-number"}],"outputs":{},"outputAnchors":[{"id":"conversationalAgent_0-output-conversationalAgent-AgentExecutor|BaseChain|Runnable","name":"conversationalAgent","label":"AgentExecutor","description":"Conversational agent for a chat model. It will utilize chat specific prompts","type":"AgentExecutor | BaseChain | Runnable"}],"id":"conversationalAgent_0","selected":false},"width":300,"height":435,"positionAbsolute":{"x":1403.3010943710588,"y":-1105.4779717197387},"selected":true,"dragging":false},{"id":"bufferMemory_0","position":{"x":887.9276071927261,"y":-781.891879856189},"type":"customNode","data":{"label":"Buffer Memory","name":"bufferMemory","version":2,"type":"BufferMemory","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/memory/BufferMemory/memory.svg","category":"Memory","description":"Retrieve chat messages stored in database","baseClasses":["BufferMemory","BaseChatMemory","BaseMemory"],"inputs":{"sessionId":"","memoryKey":"chat_history"},"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/memory/BufferMemory/BufferMemory.js","inputAnchors":[],"inputParams":[{"label":"Session Id","name":"sessionId","type":"string","description":"If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>","default":"","additionalParams":true,"optional":true,"id":"bufferMemory_0-input-sessionId-string"},{"label":"Memory Key","name":"memoryKey","type":"string","default":"chat_history","additionalParams":true,"id":"bufferMemory_0-input-memoryKey-string"}],"outputs":{},"outputAnchors":[{"id":"bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory","name":"bufferMemory","label":"BufferMemory","description":"Retrieve chat messages stored in database","type":"BufferMemory | BaseChatMemory | BaseMemory"}],"id":"bufferMemory_0","selected":false},"width":300,"height":253,"selected":false,"positionAbsolute":{"x":887.9276071927261,"y":-781.891879856189},"dragging":false},{"id":"calculator_0","position":{"x":889.4193406230049,"y":-1638.4847579416585},"type":"customNode","data":{"label":"Calculator","name":"calculator","version":1,"type":"Calculator","icon":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/Calculator/calculator.svg","category":"Tools","description":"Perform calculations on response","baseClasses":["Calculator","Tool","StructuredTool","Runnable"],"filePath":"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/tools/Calculator/Calculator.js","inputAnchors":[],"inputParams":[],"inputs":{},"outputs":{},"outputAnchors":[{"id":"calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable","name":"calculator","label":"Calculator","description":"Perform calculations on response","type":"Calculator | Tool | StructuredTool | Runnable"}],"id":"calculator_0","selected":false},"width":300,"height":143,"selected":false,"positionAbsolute":{"x":889.4193406230049,"y":-1638.4847579416585},"dragging":false}],"edges":[{"source":"chatOpenAI_0","sourceHandle":"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable","target":"conversationalAgent_0","targetHandle":"conversationalAgent_0-input-model-BaseChatModel","type":"buttonedge","id":"chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalAgent_0-conversationalAgent_0-input-model-BaseChatModel"},{"source":"bufferMemory_0","sourceHandle":"bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory","target":"conversationalAgent_0","targetHandle":"conversationalAgent_0-input-memory-BaseChatMemory","type":"buttonedge","id":"bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationalAgent_0-conversationalAgent_0-input-memory-BaseChatMemory"},{"source":"calculator_0","sourceHandle":"calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable","target":"conversationalAgent_0","targetHandle":"conversationalAgent_0-input-tools-Tool","type":"buttonedge","id":"calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-conversationalAgent_0-conversationalAgent_0-input-tools-Tool"}],"viewport":{"x":37.32260273515851,"y":1053.391257602917,"zoom":0.6218497014783928}}